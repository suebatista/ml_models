{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9Q8NDsD8GJb"
      },
      "source": [
        "# Naive Bayes\r\n",
        "\r\n",
        "There are three types of Naive Bayes model under the scikit-learn library:\r\n",
        "\r\n",
        "**Gaussian**: It is used in classification and it assumes that features follow a normal distribution.\r\n",
        "\r\n",
        "**Multinomial**: It is used for discrete counts. For example, let’s say, we have a text classification problem. Here we can consider Bernoulli trials which is one step further and instead of “word occurring in the document”, we have “count how often word occurs in the document”, you can think of it as “number of times outcome number x_i is observed over the n trials”.\r\n",
        "\r\n",
        "**Bernoulli**: The binomial model is useful if your feature vectors are binary (i.e. zeros and ones). One application would be text classification with ‘bag of words’ model where the 1s & 0s are “word occurs in the document” and “word does not occur in the document” respectively.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "**Pros:**\r\n",
        "*   Easy implementation\r\n",
        "*   Fast\r\n",
        "*   It works with binary and multiclass problems/ discrete or continous variables\r\n",
        "\r\n",
        "**Cons**\r\n",
        "\r\n",
        "*   Independente predictors: It is considered a naive model because it doesn't consider the relationship between features. Eg: For example, an animal may be considered as a cat if it has cat eyes, whiskers and a long tail. Even if these features depend on each other or upon the existence of the other features, all of these properties independently contribute to the probability that this animal is a cat and that is why it is known as ‘Naive’. Each one of these features will be treat *independently.* That situation is very hard to happen in the real world.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "*Example:* The Student will be a pass if he wears a “red” color dress on the exam day. We can solve it using above discussed method of posterior probability.\r\n",
        "By Bayes Theorem, P(Pass| Red) = P( Red| Pass) * P(Pass) / P (Red).\r\n",
        "From the values, let us assume \r\n",
        "* P (Red|Pass) = 3/9 = 0.33,\r\n",
        "* P(Red) = 5/14 = 0.36, \r\n",
        "* P( Pass)= 9/14 = 0.64. \r\n",
        "So, **P (Pass| Red) = 0.33 * 0.64 / 0.36 = 0.60**, which has higher probability.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27i3x6L1ID6i"
      },
      "source": [
        "# Python implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uLEiKyVcB_3"
      },
      "source": [
        "**Iris Flower Dataset** \r\n",
        "\r\n",
        "It consists of 3 classes of flowers. In this, there are 4 independent variables namely the, sepal_length, sepal_width, petal_length and petal_width. The dependent variable is the species which we will predict using the four independent features of the flowers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ol4RumLlfz"
      },
      "source": [
        "**1) Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17V36TaicP0N"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from sklearn import datasets"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZeVEB_4LbZQ"
      },
      "source": [
        "**2) Create dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JPrRzC8adB_F",
        "outputId": "5f59c3e0-aa8b-4911-fbc3-dd188eba14c8"
      },
      "source": [
        "dataset = pd.read_csv('https://raw.githubusercontent.com/mk-gurucharan/Classification/master/IrisDataset.csv')\r\n",
        "X = dataset.iloc[:,:4].values\r\n",
        "y = dataset['species'].values\r\n",
        "dataset.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnRD75p-dixa"
      },
      "source": [
        "**3) Splitting the dataset into the Training set and Test set**\r\n",
        "\r\n",
        "Once we have obtained our data set, we have to split the data into the training set and the test set. In this data set, there are 150 rows with 50 rows of each of the 3 classes. As each class is given in a continuous order, we need to randomly split the dataset. Here, we have the test_size=0.2, which means that 20% of the dataset will be used for testing purpose as the test set and the remaining 80% will be used as the training set for training the Naive Bayes classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BSUSdYn3zB4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTOXWb1Se7qc"
      },
      "source": [
        "**4) Feature Scaling:**\r\n",
        "\r\n",
        "The dataset is scaled down to a smaller range using the Feature Scaling option. In this, both the X_train and X_test values are scaled down to smaller values to improve the speed of the program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS3Y1U-9e_Gr"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "sc = StandardScaler()\r\n",
        "X_train = sc.fit_transform(X_train)\r\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyj0Td5PfVun"
      },
      "source": [
        "**5) Training the Naive Bayes Classification model on the Training Set**\r\n",
        "\r\n",
        "In this step, we introduce the class GaussianNB that is used from the sklearn.naive_bayes library. Here, we have used a Gaussian model, there are several other models such as Bernoulli, Categorical and Multinomial. Here, we assign the GaussianNB class to the variable classifier and fit the X_train and y_train values to it for training purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQbtKeBQfUIv",
        "outputId": "31c6489b-c28d-44aa-ccd3-d842510d1731"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "classifier = GaussianNB()\r\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmTtKYxdirSb"
      },
      "source": [
        "**6) Predicting the Test set results**\r\n",
        "\r\n",
        "Once the model is trained, we use the the classifier.predict() to predict the values for the Test set and the values predicted are stored to the variable y_pred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz91y_MriqA1",
        "outputId": "333ec59a-b7a0-4815-fd5e-6fc1c756e54b"
      },
      "source": [
        "y_pred = classifier.predict(X_test) \r\n",
        "y_pred"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'virginica', 'versicolor', 'versicolor', 'setosa',\n",
              "       'virginica', 'setosa', 'versicolor', 'versicolor', 'setosa',\n",
              "       'setosa', 'setosa', 'virginica', 'setosa', 'versicolor',\n",
              "       'versicolor', 'virginica', 'setosa', 'setosa', 'versicolor',\n",
              "       'virginica', 'versicolor', 'versicolor', 'versicolor', 'virginica',\n",
              "       'virginica', 'setosa', 'virginica', 'versicolor', 'virginica'],\n",
              "      dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQE3SO8llEMT"
      },
      "source": [
        "**7)Confusion Matrix and Accuracy**\r\n",
        "This is a step that is mostly used in classification techniques. In this, we see the Accuracy of the trained model and plot the confusion matrix.\r\n",
        "The confusion matrix is a table that is used to show the number of correct and incorrect predictions on a classification problem when the real values of the Test Set are known. It is of the format.The True values are the number of correct predictions made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_mZEzollDkt",
        "outputId": "b5e16b75-37e5-4128-ab76-a925fd1a3119"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "cm = confusion_matrix(y_test, y_pred)\r\n",
        "from sklearn.metrics import accuracy_score \r\n",
        "print (\"Accuracy : \", accuracy_score(y_test, y_pred))\r\n",
        "cm"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.9666666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  0,  0],\n",
              "       [ 0, 11,  1],\n",
              "       [ 0,  0,  8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MaUIzLunS5w"
      },
      "source": [
        "From the above confusion matrix, we infer that, out of 30 test set data, 29 were correctly classified and only 1 was incorrectly classified. This gives us a high accuracy of 96.67%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFOwqfwzocEw"
      },
      "source": [
        "Step 8: Comparing the Real Values with Predicted Values\r\n",
        "In this step, a Pandas DataFrame is created to compare the classified values of both the original Test set (y_test) and the predicted results (y_pred)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Jpw46okQnR7_",
        "outputId": "f86aa169-0cb5-4a5c-9f36-d258f61b90df"
      },
      "source": [
        "df = pd.DataFrame({'Real Values':y_test[0:10], 'Predicted Values':y_pred[0:10]})\r\n",
        "df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Real Values</th>\n",
              "      <th>Predicted Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>setosa</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>virginica</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>setosa</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>setosa</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>versicolor</td>\n",
              "      <td>versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>setosa</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Real Values Predicted Values\n",
              "0      setosa           setosa\n",
              "1   virginica        virginica\n",
              "2  versicolor       versicolor\n",
              "3  versicolor       versicolor\n",
              "4      setosa           setosa\n",
              "5  versicolor        virginica\n",
              "6      setosa           setosa\n",
              "7  versicolor       versicolor\n",
              "8  versicolor       versicolor\n",
              "9      setosa           setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBi6GG6SCsET"
      },
      "source": [
        "# Tips to improve the power of Naive Bayes Model:\r\n",
        "\r\n",
        "* If continuous features do not have normal distribution, we should use transformation or different methods to **convert it in normal distribution**.\r\n",
        "* If test data set has zero frequency issue, apply smoothing techniques like “***Laplace Correction***” to predict the class of test data set.\r\n",
        "* **Remove correlated features**, as the highly correlated features are voted twice in the model and it can lead to over inflating importance.\r\n",
        "* Naive Bayes classifiers has limited options for parameter tuning like alpha=1 for smoothing, fit_prior=[True|False] to learn class prior probabilities or not and some other options. I would recommend to **focus on your  pre-processing of data and the feature selection.**\r\n",
        "* You might think to apply some classifier combination technique like ensembling, bagging and boosting but these methods would not help. Actually, “ensembling, boosting, bagging” won’t help since their purpose is to reduce variance. **Naive Bayes has no variance to minimize.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzkLSNZ2Z-m0"
      },
      "source": [
        "*Example:* The Student will be a pass if he wears a “red” color dress on the exam day. We can solve it using above discussed method of posterior probability.\r\n",
        "By Bayes Theorem, P(Pass| Red) = P( Red| Pass) * P(Pass) / P (Red).\r\n",
        "From the values, let us assume \r\n",
        "* P (Red|Pass) = 3/9 = 0.33,\r\n",
        "* P(Red) = 5/14 = 0.36, \r\n",
        "* P( Pass)= 9/14 = 0.64. \r\n",
        "So, **P (Pass| Red) = 0.33 * 0.64 / 0.36 = 0.60**, which has higher probability."
      ]
    }
  ]
}